var documenterSearchIndex = {"docs":
[{"location":"svd/#Singular-Value-Decomposition-(SVD)","page":"SVD","title":"Singular Value Decomposition (SVD)","text":"","category":"section"},{"location":"svd/#Introduction","page":"SVD","title":"Introduction","text":"","category":"section"},{"location":"svd/","page":"SVD","title":"SVD","text":"The SVD is a matrix factorization technique that decomposes any matrix to a unique set of matices. The SVD is used for dimension reduction, trend analysis, and potentially for the clustering of a multivariate dataset. SVD is an exploratory approach to the data analysis and therefore it is an unsuprevised approach. In other words, you will only need the X block matrix. However, where the Y matrix/vector is available, it (i.e. Y) can be used for building composit models or assess the quality of the clustering. ","category":"page"},{"location":"svd/#How?","page":"SVD","title":"How?","text":"","category":"section"},{"location":"svd/","page":"SVD","title":"SVD","text":"In SVD the matrix X_{m \\times n} is decomposed into the matrices ``U_{m \\times n}, D_{n \\times n}``, and V_n times n^T. The matrix U_m times n is the left singular matrix and it represents a rotation in the matrix space. The D_n times n is diagonal matrix and contains the singular values. This matix may be indicated with different symbols such as Sigma_n times n. The D_n times n matrix in the geometrical space represents an act of stratching. Each singular value is the degree and/or weight of stratching. We use the notation D_n times n to remind ourselves that this is a diagonal matrix. Finally, V_n times n^T is called the right singular matrix and is associated with rotation. Overall, SVD geometrically is a combination of a rotation, a stratching, and a second rotation.","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"The two matrics U_m times n and V_n times n^T are very special due to their unitary properties.","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"\nU^T times U = U times U^T = I\nV^T times V = V times V^T = I\n","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"Therefore the general matrix expression of SVD is the following: ","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"X = UDV^T\n","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"To deal with the non-square matrices, we have to convert our X matrix to X^T times X. This implies that our SVD equation will become the following: ","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"X^TX = (UDV^T)^T times UDV^T\n","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"And after a little bit of linear algebra: ","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"X^TX = VD^T times DV^T  \nand \n\nXV = UD\n","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"This is a system of two equations with two variables that can be solved. Before looking at an example of such system let's remind ourselves that VD^T times DV^T is the solution of eigenvalue/eigenvector decomposition of X^TX. This means that both D and V^T can be calculated by calculating the eigenvalues and eigenvectors of X^TX. Therefore we can calculate D and V as follows:","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"\nD = sqrteigenvalues(X^TX) \nV = eigenvector(X^TX)\n","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"Once we know V, we can use that and the second equation of SVD to calculate the last part i.e. the matrix U. ","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"U = XVD^-1 \n","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"Please note that D^-1 denotes the inverse or pseudo-inverse of the matrix D.  ","category":"page"},{"location":"svd/#Practical-example","page":"SVD","title":"Practical example","text":"","category":"section"},{"location":"svd/","page":"SVD","title":"SVD","text":"Let's do the SVD calculations together for the below matrix: ","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"using ACS\n\nX = [5 -5;-1 7;1 10]\n","category":"page"},{"location":"svd/#Step-1:-X{T}X","page":"SVD","title":"Step 1: X^TX","text":"","category":"section"},{"location":"svd/","page":"SVD","title":"SVD","text":"# The function transpose(-) is part of LinearAlgebra.jl package that has been automatically installed via ACS.jl package.\n# Not all the functions of LinearAlgebra.jl are exported within the ACS.jl enviornment. \nXtX = transpose(X)*X \n","category":"page"},{"location":"svd/#Step-2:-calculation-of-*D*,-*V*,-and-*U*","page":"SVD","title":"Step 2: calculation of D, V, and U","text":"","category":"section"},{"location":"svd/","page":"SVD","title":"SVD","text":"\nD = diagm(sqrt.(eigvals(XtX))) # A diagonal matrix is generated\n","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"\nV = eigvecs(XtX) # Right singular matrix\n\n","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"\nU = X*V*pinv(D)\t# Left singular matrix\n\n","category":"page"},{"location":"svd/#Builtin-function","page":"SVD","title":"Builtin function","text":"","category":"section"},{"location":"svd/","page":"SVD","title":"SVD","text":"The same calculations can be done with the fucntion svd(-) of ACS package provided via LinearAlgebra.jl package. ","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"\n out = svd(X)\n","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"\n D = diagm(out.S) # The singular value matrix\n","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"\n U = out.U # Left singular matrix\n","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"\n V = transpose(out.Vt) # Right singular matrix\n","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"Please note that the builtin function sorts the singular values in descending order and consequently the other two matrices are also sorted following the same. Additionally, for ease of calculations the builtin function generates the mirror image of the U and V matrices. These differences essentially do not impact your calculations at all, as long as they are limited to what is listed above.","category":"page"},{"location":"svd/#Step-3-calculation-of-\\hat{X}","page":"SVD","title":"Step 3 calculation of hatX","text":"","category":"section"},{"location":"svd/","page":"SVD","title":"SVD","text":"Using both the manual method and the builtin function, you can calculate hatX following the below operation. ","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"\nX_hat = U*D*transpose(V)\n","category":"page"},{"location":"svd/#Applications","page":"SVD","title":"Applications","text":"","category":"section"},{"location":"svd/","page":"SVD","title":"SVD","text":"As mentioned above SVD has several applications in different fields. Here we will focus on three, namely: dimension reduction, clustering/trend analysis, and multivariate regression. ","category":"page"},{"location":"svd/#Dimension-reduction","page":"SVD","title":"Dimension reduction","text":"","category":"section"},{"location":"svd/","page":"SVD","title":"SVD","text":"To show case the power of SVD in dimension reduction we will use the Iris dataset from Rdatasets. ","category":"page"},{"location":"svd/","page":"SVD","title":"SVD","text":"using ACS\n\ndata = dataset(\"datasets\", \"iris\")\ndescribe(data) # Simerizes the dataset\n","category":"page"},{"location":"svd/#Clustering-and-trend-analysis","page":"SVD","title":"Clustering and trend analysis","text":"","category":"section"},{"location":"#Advanced-Statistics-and-Chemometrics-(ACS)","page":"Home","title":"Advanced Statistics and Chemometrics (ACS)","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A documentation built for the ACS course to help the students during the lectures and for exame preparation ","category":"page"}]
}
